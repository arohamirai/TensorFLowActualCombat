{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet\n",
    "http://blog.csdn.net/marsjhao/article/details/73088850\n",
    "也称为Inception Net。\n",
    "\n",
    "ILSVRC 2014比赛冠军（和VGGNet 同年），Inception V1 top-5分类错误率为6.67%。\n",
    "\n",
    "22层网络。\n",
    "http://blog.csdn.net/marsjhao/article/details/73088850\n",
    "\n",
    "## Inception V1\n",
    "\n",
    "GoogLeNet网络结构图（Inception V1）\n",
    "![GoogLeNet](http://wx3.sinaimg.cn/mw690/006H1aMCgy1fgjnqg6onkj30fp1yxtbm.jpg)\n",
    "<center>GoogLeNet网络结构图（Inception V1）</center>\n",
    "\n",
    "**亮点：**\n",
    "1. 其最大的优势在于控制 了参数量（也就控制了计算量）的同时，仍然能够获得非常好的分类性能；\n",
    "2. 较多使用1x1卷积核，大幅降低参数量；\n",
    "3. 去除了最后的全连接层，用平均池化层（即将图片尺寸变为1x1）取代；\n",
    "4. 精心设计的Inception Module，提高了参数的利用效率。\n",
    "\n",
    "**一些细节问题：**\n",
    "1. Inception net 要求输入图像的像素值在 0-255 区间内，而不是 0-1，如果原始图像的像素值在 0-1，需要在乘以 255；\n",
    "2. Inception net 的输出是 softmax-function。\n",
    "\n",
    "3. 为什么使用了较多 1×1 的卷积？ \n",
    "\n",
    "    1). 图片数据天然地邻近区域的数据相关性较高，也即可通过卷积操作使相邻的像素点连接在一起。我们可十分方便构造多个卷积核，在同一空间位置但不同通道的卷积核的输出结果相关性较高。\n",
    "    \n",
    "    2). 因此一个 1×1 的卷积就可以很自然地将这些相关性很高的、在同一空间位置但不同通道的特征连接在一起，这也正是 1×1 的卷积会频繁地应用到 Inception Net 中的原因。\n",
    "    \n",
    "    3). 1×1 卷积所连接的节点的相关性是最高的，而稍微大一点尺寸的卷积，3×3、5×5 的卷积所连接的节点相关性也很高，因此可进一步地使用一些稍大尺寸的卷积，增加特征多样性（diversity）；\n",
    "\n",
    "**Inception Module 结构图**\n",
    "![InceptionNet](https://ws1.sinaimg.cn/large/006H1aMCgy1fgjkcodd5yj30go08l0tv.jpg)\n",
    "\n",
    "Inception Net 的主要目标就是找到最优的稀疏结构单元（即 Inception Module）, 一个 \"好\"的稀疏结构，应该三符合Hebbian原理的。\n",
    "\n",
    "\n",
    "**Hebbian原理**\n",
    "\n",
    "反射活动的持续与重复会导致神经元稳定性的持久性提升……当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了。这一理论经常会被总结为“一起发射的神经元连在一起”（Cells that fire together, wire together）。这可以用于解释“联合学习”（associative learning），在这种学习中通过对神经元的刺激使得神经元间的突触强度增加。这样的学习方法被称为赫布型学习（Hebbian learning）。\n",
    "\n",
    "\n",
    "**Google Inception Net家族**\n",
    "\n",
    "[v1] Going Deeper withConvolutions, 6.67% test error，2014.9\n",
    "\n",
    "论文地址：http://arxiv.org/abs/1409.4842\n",
    "\n",
    "[v2] Batch Normalization:Accelerating Deep Network Training by Reducing Internal Covariate Shift, 4.8% test error，2015.2\n",
    "\n",
    "论文地址：http://arxiv.org/abs/1502.03167\n",
    "\n",
    "[v3] Rethinking theInception Architecture for Computer Vision, 3.5%test error，2015.12\n",
    "\n",
    "论文地址：http://arxiv.org/abs/1512.00567\n",
    "\n",
    "[v4] Inception-v4,Inception-ResNet and the Impact of Residual Connections on Learning, 3.08% test error，2016.2\n",
    "\n",
    "论文地址：http://arxiv.org/abs/1602.07261\n",
    "\n",
    "## Inception V2\n",
    "\n",
    "**亮点**\n",
    "1. Inception V2学习了VGGNet，用两个3*3的卷积代替5*5的大卷积（用以降低参数量并减轻过拟合）;\n",
    "2. 提出了著名的Batch Normalization（以下简称BN）方法;\n",
    "3. 一些调整：\n",
    "    1). 增大学习速率并加快学习衰减速度以适用BN规范化后的数据；\n",
    "    2). 去除Dropout并减轻L2正则（因BN已起到正则化的作用）；\n",
    "    3). 去除LRN；\n",
    "    4). 更彻底地对训练样本进行shuffle；\n",
    "    5). 减少数据增强过程中对数据的光学畸变（因为BN训练更快，每个样本被训练的次数更少，因此更真实的样本对训练更有帮助）。\n",
    "\n",
    "在使用了这些措施后，Inception V2在训练达到Inception V1的准确率时快了14倍，并且模型在收敛时的准确率上限更高。\n",
    "\n",
    "**Batch Normalization(BN方法)**\n",
    "\n",
    "BN在用于神经网络某层时，会对每一个mini-batch数据的内部进行标准（normalization）处理，使输出规范化到N(0,1)的正态分布，减少了InternalCovariate Shift（内部神经元分布的改变）。BN的论文指出，传统的深度神经网络在训练时，每一层的输入的分布都在变化，导致训练变得困难，**我们只能使用一个很小的学习速率解决这个问题**。而对每一层使用BN之后，我们就可以有效地解决这个问题，学习速率可以增大很多倍，达到之前的准确率所需要的迭代次数只有1/14，训练时间大大缩短。而达到之前的准确率后，可以继续训练，并最终取得远超于Inception V1模型的性能——top-5错误率4.8%，已经优于人眼水平。因为BN某种意义上还起到了正则化的作用，所以可以减少或者取消Dropout，简化网络结构。\n",
    "\n",
    "## Inception V3\n",
    "**亮点**\n",
    "1. 引入了Factorization into smallconvolutions的思想，将一个较大的二维卷积拆成两个较小的一维卷积（下图一）；\n",
    "2. 优化了Inception Module的结构，现在Inception Module有35*35、17*17和8*8三种不同结构(下图二)。\n",
    "![](https://ws1.sinaimg.cn/large/006H1aMCgy1fgjmwf8hgzj305q07t3z6.jpg)\n",
    "<center>图一 将一个3*3卷积拆成1*3卷积和3*1卷积</center>\n",
    "![](https://ws1.sinaimg.cn/large/006H1aMCgy1fgjmxg5wdej30y50dc0uv.jpg)\n",
    "<center>图二 Inception V3中三种结构的InceptionModule</center>\n",
    "\n",
    "## Inception V4\n",
    "**亮点**\n",
    "结合了微软的ResNet，极大地加速训练，同时性能也有提升，得到一个Inception-ResNet v2网络，同时还设计了一个更深更优化的Inception v4模型，能达到与Inception-ResNet v2相媲美的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
